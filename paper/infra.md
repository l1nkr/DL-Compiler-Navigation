# Infrastructe

## Bring You Own Codegen

问题：硬件厂商新增硬件（AI芯片）时，需要定制一套编译栈。
- 难以支持所有算子（硬件特性）
- 算子、模型迭代快，所以需要经常维护
- 已有工作难以复用，必须从头开始定制

原则：将计算图进行拆分，新硬件支持的就新硬件执行，不支持的就交给cpu or gpu 执行。

方案：
- graph 划分
  - 加速器原生支持常见算子的融合（如 conv2d bias relu）。因此可以直接映射过去。
  - 划出加速器支持的算子
  - 选择哪些应该放到加速器上执行。主要是访存和计算之间的 trade off，看看值不值得放下去。
- 特定优化（加载到加速器的区域可能需要一些依赖于硬件的优化，这些优化无法从深度学习编译器直接访问，因为这些优化要么是专有的，要么需要特定的硬件信息）
  - 量化
  - 布局转换
- 代码生成
  - host 部分调用已有mlc如tvm
  - 加速器部分调用专用的

问题：
offload到硬件上跑的还是手工库
