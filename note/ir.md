## AI框架中图层IR的作用
现在主流的AI框架都有图层IR，好的图层IR有利于AI模型的编译优化和执行，是AI框架进行高效训练和推理的基础。

从训练的角度看，目前业界的AI框架有三种执行模式：**Eager执行模式、图执行模式和Staging(混合)执行模式**，其中高性能模式下（Graph执行模式和Staging执行模式）都要基于图层IR：

- Eager执行模式一般是利用宿主语言（现在主要是Python）的特性进行解释执行，里面使用了重载和Tape的一些技巧。
  
- Graph执行模式主要是拿到AI模型的图结构，然后进行编译优化和执行，这里的编译优化和执行就要基于图IR。
  - 额外提一下，现在有三种方法拿到AI模型的图结构，第一种是程序员使用API构图（TF1.x版本等）；第二种是Tracing JIT（JAX带来的潮流，现在TF2.0/Pytorch等都支持），即把用户的模型脚本模拟跑一下，拿到正向的执行序列，然后基于这个序列进行构图，好处是与Eagle模式比较容易匹配，实现简单，缺点是控制流的转换比较麻烦、执行序列如果与算子执行结果相关的话不好实现、不容易处理副作用，所以TF的AutoGraph还需要结合AST分析解决控制流转换的问题；第三种是AST JIT（Pytorch的TorchScript），基于Python的AST进行构图，优点是转换的功能可以比较全面，包括控制流等，缺点是实现复杂，许多Python动态特性实现起来工作量大。
  
- Staging执行模式类似在Eager模式中，通过Python修饰符，对部分子图进行编译执行加速（使用Tracing JIT或者AST JIT），也会用到图IR。
  
从推理的角度看，AI框架生成最终的推理模型时需要进行大量的编译优化，如量化、剪枝等，一般都在图层IR上进行，同时最终的推理模型格式也是直接或者间接使用到图层IR。

### AI框架图层IR的需求和挑战
与其他通用的IR相比，AI框架的图层IR有一些比较特殊的需求和挑战：

- 张量表达
AI的模型主要处理的是张量数据，这个与普通的应用差别是比较大的，不过增加张量数据类型对编译器的IR来说并不是件困难的事情。

- 自动微分
可微分是AI模型开发与一般应用开发区别最大的地方，现代的AI框架都会提供自动微分的功能，挑战在于实现的简洁性、性能以及未来高阶微分的扩展能力。

- JIT能力
无论是图模式还是Staging模式，从算法工程师角度看，由于没有显示编译的步骤，都可以认为是JIT方式。对于JIT来说，编译性能是一个主要挑战。

- 隐式并行
从开发者来说，有两种并行方式，一种是是显式并行，开发者明确告诉系统哪里并行，比如显示启动多线程/添加并行修饰符；还有一种方式是隐式并行，通过编译器来分析依赖，自动实现并行。一般而言，传统的CFG+BB的编译器，由于程序分析使用全序分析，方便做显式并行；函数式的编译器理论上易于数据依赖分析，方便进行隐式并行优化。有趣的是，在深度学习场景中，Kernel执行占了大部分开销，在运行时实现异步并发的模式也可以显著提升整体性能，隐式并行的作用相对会被弱化，但是想要实现极致性能，隐式并行还是有作用的。

- Loop优化
AI的计算涉及大量的Tensor运算，对编译器来说就是Loop优化（张量—>标量—>向量化），不过这个挑战主要还是在算子层的IR上。

当然，图层IR也是是一种编译器IR，应该具备通用性，包括类型系统、控制流和数据流分析、副作用消除等基本的功能。

https://zhuanlan.zhihu.com/p/263420069